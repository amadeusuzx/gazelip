{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from network import R2Plus1DClassifier\n",
    "import torch\n",
    "\n",
    "lip_model = R2Plus1DClassifier(num_classes=28, layer_sizes=[2,2,2,2,2,2])\n",
    "state_dicts = torch.load(\"smartTV4080\", map_location = torch.device(\"cuda:0\"))\n",
    "lip_model.load_state_dict(state_dicts[\"state_dict\"])\n",
    "lip_model.eval()\n",
    "lip_model.cuda()\n",
    "1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "clone_model = nn.Linear(1024,28)\n",
    "clone_model.load_state_dict(lip_model.linear.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(10000):\n",
    "    models.append(nn.Linear(1024,28).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() \n",
    "del buffer\n",
    "del lip_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 40 ms\n",
      "Wall time: 35 ms\n",
      "Wall time: 38 ms\n",
      "Wall time: 45 ms\n",
      "Wall time: 56 ms\n",
      "Wall time: 63 ms\n",
      "Wall time: 72 ms\n",
      "Wall time: 73 ms\n",
      "Wall time: 84 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in range(1,10):\n",
    "    buffer  = torch.zeros(1,3,30*i,30,60).cuda()\n",
    "    %time output =  lip_model(buffer).cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_foo = torch.jit.trace( lip_model,buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(lip_model,               # model being run\n",
    "                  buffer,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"zxsuSmartTV4080.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {2 : 'time_step'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "print(onnxruntime.get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "import psutil\n",
    "so = onnxruntime.SessionOptions()\n",
    "so.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "so.optimized_model_filepath = \"optimized.onnx\"\n",
    "so.intra_op_num_threads=psutil.cpu_count(logical=True)\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\"zxsuSmartTV4080.onnx\", so)\n",
    "\n",
    "buffer = np.zeros((1,3,200,50,100),dtype = \"float32\")\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: buffer}\n",
    "\n",
    "# %time torch_out = lip_model(buffer)\n",
    "\n",
    "# # compare ONNX Runtime and PyTorch results\n",
    "# np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = np.random.rand(1,3,100,40,80).astype('float32')\n",
    "ort_inputs = {ort_session.get_inputs()[0].name:buffer }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time ort_outs = ort_session.run(None, ort_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session.get_inputs()[0].name: to_numpy(buffer)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"2020-10-18_180521_161.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in range(240):\n",
    "    a.append(cv2.cvtColor(cap.read()[1],cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a[102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.sum(a[102] == a[101])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(a[102] != a[101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generalFucDict = [\"scroll_up\",\"scroll_down\",\"go_back\",\"go_forward\"]\n",
    "sideMenuFuncDict = [\"home\",\"trending\",\"subscription\",\"originals\",\"library\"]\n",
    "navigationBarFuncDic = [\"voice_search\",\"profile\",\"notifications\",\"homepage\"]\n",
    "thumbnailFuncDict = [\"play\",\"watch_later\",\"add_to_queue\"]\n",
    "miniplayerFuncDict = [\"expand\",\"play\",\"stop\",\"previous\",\"next\"]\n",
    "mainPlayerFuncDict = [\"caption\",\"play\",\"stop\",\"go_back\",\"go_forward\",\"previous\",\"next\",\"volume_up\",\"volume_down\"]\n",
    "queueHeadFuncDict = [\"expand\",\"save\"]\n",
    "queueFuncDict = [\"delete\",\"play\"]\n",
    "likeMenuFuncDict = [\"like\",\"dislike\",\"share\",\"save\"]\n",
    "# channelListFuncDict = [\"music\",\"gaming\",\"news\",\"movies\"]\n",
    "commands = ['caption','play','stop','go_back','go_forward','previous','next','volume_up','volume_down','maximize','expand','delete','save','like','dislike','share','add_to_queue','watch_later','home','trending','subscription','original','library','profile','notification','scroll_up','scroll_down','click']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(pyautogui.press(\"f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "i = mp.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.874992609024048\n"
     ]
    }
   ],
   "source": [
    "t=time.time()\n",
    "for _ in range(100):\n",
    "    i.get()\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009999275207519531\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "t=time.time()\n",
    "while i<1000000:\n",
    "    pass\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
